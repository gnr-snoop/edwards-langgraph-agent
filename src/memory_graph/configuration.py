"""Define the configurable parameters for the memory service."""
import os
from dataclasses import field, fields
from typing import Any, Literal, Optional, List

from langgraph.config import get_config
from typing_extensions import Annotated

from pydantic import BaseModel, Field
from dataclasses import dataclass

@dataclass(kw_only=True)
class MemoryConfig():
    """Configuration for memory-related operations."""

    """This tells the model how to reference the function and organizes related memories within the namespace."""
    name: str
    """Description for what this memory type is intended to capture."""
    description: str

    """The JSON Schema of the memory document to manage."""
    schema: BaseModel
    """The system prompt to use for the memory assistant."""
    system_prompt: str = ""

    """Whether to allow deleting existing memories that are outdated or contradicted by new information"""
    delete: bool = False

    """Whether to continuously patch the memory, or treat each new generation as a new memory.

    Patching is useful for maintaining a structured profile or core list 
    of memories. Inserting is useful for maintaining all interactions and
    not losing any information.

    For patched memories, you can GET the current state at any given time.
    For inserted memories, you can query the full history of interactions.
    """
    update_mode: Literal["patch", "insert"] = field(default="patch")


@dataclass(kw_only=True)
class Configuration:
    """Main configuration class for the memory graph system."""

    user_id: str = "default_user"
    """The ID of the user to remember in the conversation."""
    model: Annotated[str, {"__template_metadata__": {"kind": "llm"}}] = field(
        default="azure_openai:gpt-4.1",
        metadata={
            "description": "The name of the language model to use for the agent. "
            "Should be in the form: provider/model-name."
        },
    )

    """The models to use for generating memories. """
    memory_types: list[MemoryConfig] = field(default_factory=list)

    max_extraction_steps: int = 1
    """The maximum number of steps to take when extracting memories."""

    @classmethod
    def from_context(cls) -> "Configuration":
        """Create a Configuration instance from a RunnableConfig."""
        try:
            config = get_config()
            configurable = (
                config["configurable"] if config and "configurable" in config else {}
            )
        except RuntimeError:
            configurable = {}

        values: dict[str, Any] = {
            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))
            for f in fields(cls)
            if f.init
        }
        values["memory_types"] = DEFAULT_MEMORY_CONFIGS.copy()


        return cls(**{k: v for k, v in values.items() if v})


class QueriesMemory(BaseModel):
    sql_query: str = Field(..., description="The SQL generated by the agent in response to the user's request.")
    user_query: str = Field(..., description="The user's original query.")
    explanation: str = Field(..., description="An explanation of the SQL query, if available.")

class UserMemory(BaseModel):
    user_name: Optional[str] = Field(None, description="The user's preferred name")
    age: Optional[int] = Field(None, description="The user's age")
    interests: Optional[List[str]] = Field(None, description="A list of the user's interests")
    occupation: Optional[str] = Field(None, description="The user's current occupation or profession")
    conversation_preferences: Optional[List[str]] = Field(
        None, description="A list of the user's preferred conversation styles, pronouns, topics they want to avoid, etc."
    )

class NoteMemory(BaseModel):
    context: str = Field(..., description="The situation or circumstance where this memory may be relevant. Include any caveats or conditions that contextualize the memory.")
    content: str = Field(..., description="The specific information, preference, or event being remembered.")

class TransactionMemory(BaseModel):
    transaction_type: str = Field(..., description="The type of transaction (e.g., 'creacion hallazgo', 'busqueda laboral', 'refund').")
    description: Optional[str] = Field(None, description="A brief description of the transaction.")
    fields: Optional[dict] = Field(None, description="Additional fields specific to the transaction type. i.e: ")
    status: Optional[str] = Field(None, description="The current status of the transaction (e.g., 'completed', 'pending', 'failed').")

class ResumeMemory(BaseModel):
    content: str = Field(..., description="Resume of all the interactions with the user.")


DEFAULT_MEMORY_CONFIGS = [
    MemoryConfig(
        name="Transactions",
        description="Save transactions the user has made to the agent for later recall.",
        update_mode="insert",
        delete=True,
        system_prompt="Extract only information about QMS or HRM transactions of the user in the conversation. Delete related memories when completed.",
        schema=TransactionMemory
    ),
    MemoryConfig(
        name="User",
        description="Update this document to maintain up-to-date information about the user in the conversation.",
        update_mode="patch",
        schema=UserMemory
    ),
    MemoryConfig(
        name="Resume",
        description="Save notable memories the user has shared with you for later recall.",
        update_mode="patch",
        system_prompt="Provide a detailed recap covering key topics, decisions, and open points.",
        schema=ResumeMemory
    ),
]